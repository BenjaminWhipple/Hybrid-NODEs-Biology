{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2cc1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Version : 0.4.6\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "print(\"JAX Version : {}\".format(jax.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9285a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "from jax import grad, value_and_grad\n",
    "from jax import jit, vmap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f993cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800,), (200,), (800,), (200,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from jax import numpy as jnp\n",
    "\n",
    "#X, Y = datasets.load_boston(return_X_y=True)\n",
    "X = jnp.linspace(0,jnp.pi,1000)\n",
    "Y = jnp.sin(X)\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=123)\n",
    "\n",
    "X_train = jnp.array(X_train, dtype=jnp.float32)\n",
    "X_test = jnp.array(X_test, dtype=jnp.float32)\n",
    "Y_train = jnp.array(Y_train, dtype=jnp.float32)\n",
    "Y_test = jnp.array(Y_test, dtype=jnp.float32)\n",
    "\n",
    "samples = X_train.shape\n",
    "\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca6c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean = X_train.mean(axis=0)\n",
    "#std = X_train.std(axis=0)\n",
    "\n",
    "#X_train = (X_train - mean) / std\n",
    "#X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b39afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32), Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32)], [Array([[ 0.36326313,  0.67431045, -0.34833646, ..., -0.22690678,\n",
      "         0.78762126,  0.40378356],\n",
      "       [ 0.01716638,  0.8024769 , -0.50727034, ..., -0.8463812 ,\n",
      "         0.6829629 ,  0.5702553 ],\n",
      "       [ 0.9183562 , -0.54055095, -0.84586954, ..., -0.93066454,\n",
      "         0.00561404,  0.10867071],\n",
      "       ...,\n",
      "       [-0.9970796 , -0.9228153 , -0.3602624 , ...,  0.88771844,\n",
      "        -0.63122797, -0.5530937 ],\n",
      "       [-0.33314276, -0.76246595, -0.55924153, ...,  0.24797583,\n",
      "         0.73389363,  0.02865171],\n",
      "       [-0.1650505 ,  0.7162664 , -0.23983073, ...,  0.90228057,\n",
      "         0.87591887,  0.83819175]], dtype=float32), Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32)], [Array([[ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "         0.09241819, -0.08388805]], dtype=float32), Array([-0.54859734], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "def LinearLayer(weights, input_data, activation=lambda x: x):\n",
    "    w, b = weights\n",
    "    #print(weights)\n",
    "    #print(input_data)\n",
    "    out = jnp.dot(input_data, w.T) + b\n",
    "    return activation(out)\n",
    "\n",
    "def InitializeWeights(layer_sizes, seed):\n",
    "    weights = []\n",
    "\n",
    "    for i, units in enumerate(layer_sizes):\n",
    "        if i==0:\n",
    "            #w = jax.random.uniform(key=seed, shape=(units, features), minval=-1.0, maxval=1.0, dtype=jnp.float32)\n",
    "            w = jax.random.uniform(key=seed, shape=(units,), minval=-1.0, maxval=1.0, dtype=jnp.float32)\n",
    "        else:\n",
    "            w = jax.random.uniform(key=seed, shape=(units, layer_sizes[i-1]), minval=-1.0, maxval=1.0,\n",
    "                                   dtype=jnp.float32)\n",
    "\n",
    "        b = jax.random.uniform(key=seed, minval=-1.0, maxval=1.0, shape=(units,), dtype=jnp.float32)\n",
    "\n",
    "        weights.append([w,b])\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "seed = jax.random.PRNGKey(123)\n",
    "weights = InitializeWeights([1024,1024,1], seed)\n",
    "#weights = InitializeWeights([25,25], seed)\n",
    "'''\n",
    "for w in weights:\n",
    "    print(w[0].shape, w[1].shape)\n",
    "'''\n",
    "def Relu(x):\n",
    "    return jnp.maximum(x, jnp.zeros_like(x)) # max(0,x)\n",
    "\n",
    "Relu_jit = jit(Relu)\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "330b0446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0, 0, 1, 0, 4, 0, 5], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.array([-1,0,1,-2,4,-6,5])\n",
    "\n",
    "Relu(x)\n",
    "Relu_jit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "646e5e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@jit\\ndef Relu(x):\\n    return jnp.maximum(x, jnp.zeros_like(x)) # max(0,x)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "@jit\n",
    "def Relu(x):\n",
    "    return jnp.maximum(x, jnp.zeros_like(x)) # max(0,x)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f6fb4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.154145\n",
      "527.93066\n"
     ]
    }
   ],
   "source": [
    "def ForwardPass(weights, input_datapoint):\n",
    "    layer_out = input_datapoint\n",
    "\n",
    "    for i in range(len(weights[:-1])):\n",
    "        #print(weights[i])\n",
    "        #print(layer_out)\n",
    "        layer_out = LinearLayer(weights[i], layer_out, Relu_jit)\n",
    "\n",
    "    preds = LinearLayer(weights[-1], layer_out)\n",
    "\n",
    "    return preds.squeeze()\n",
    "\n",
    "preds = ForwardPass(weights, X_train[1])\n",
    "\n",
    "print(X_train[1])\n",
    "print(preds)\n",
    "#preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11f99eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "def BatchForwardPass(weights, input_data):\n",
    "    #apply forward pass to each data point\n",
    "    predictions = [ForwardPass(weights,input_data[i]) for i in range(len(input_data))]\n",
    "    preds = jnp.array(predictions)\n",
    "    return preds.squeeze()\n",
    "#'''\n",
    "print(len(BatchForwardPass(weights,X_train)))\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0facd123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32), Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32)], [Array([[ 0.36326313,  0.67431045, -0.34833646, ..., -0.22690678,\n",
      "         0.78762126,  0.40378356],\n",
      "       [ 0.01716638,  0.8024769 , -0.50727034, ..., -0.8463812 ,\n",
      "         0.6829629 ,  0.5702553 ],\n",
      "       [ 0.9183562 , -0.54055095, -0.84586954, ..., -0.93066454,\n",
      "         0.00561404,  0.10867071],\n",
      "       ...,\n",
      "       [-0.9970796 , -0.9228153 , -0.3602624 , ...,  0.88771844,\n",
      "        -0.63122797, -0.5530937 ],\n",
      "       [-0.33314276, -0.76246595, -0.55924153, ...,  0.24797583,\n",
      "         0.73389363,  0.02865171],\n",
      "       [-0.1650505 ,  0.7162664 , -0.23983073, ...,  0.90228057,\n",
      "         0.87591887,  0.83819175]], dtype=float32), Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32)], [Array([[ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "         0.09241819, -0.08388805]], dtype=float32), Array([-0.54859734], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "def MeanSquaredErrorLoss(weights, input_data, actual):\n",
    "    preds = BatchForwardPass(weights, input_data)\n",
    "    return jnp.power(actual - preds, 2).mean()\n",
    "\n",
    "MeanSquaredErrorLoss(weights, X_train, Y_train)\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ea48734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad, value_and_grad\n",
    "\n",
    "def CalculateGradients(weights, input_data, actual):\n",
    "    Grad_MSELoss = grad(MeanSquaredErrorLoss)\n",
    "    gradients = Grad_MSELoss(weights, input_data, actual)\n",
    "    return gradients\n",
    "\n",
    "gradients = CalculateGradients(weights, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1cabdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32), Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32)], [Array([[ 0.36326313,  0.67431045, -0.34833646, ..., -0.22690678,\n",
      "         0.78762126,  0.40378356],\n",
      "       [ 0.01716638,  0.8024769 , -0.50727034, ..., -0.8463812 ,\n",
      "         0.6829629 ,  0.5702553 ],\n",
      "       [ 0.9183562 , -0.54055095, -0.84586954, ..., -0.93066454,\n",
      "         0.00561404,  0.10867071],\n",
      "       ...,\n",
      "       [-0.9970796 , -0.9228153 , -0.3602624 , ...,  0.88771844,\n",
      "        -0.63122797, -0.5530937 ],\n",
      "       [-0.33314276, -0.76246595, -0.55924153, ...,  0.24797583,\n",
      "         0.73389363,  0.02865171],\n",
      "       [-0.1650505 ,  0.7162664 , -0.23983073, ...,  0.90228057,\n",
      "         0.87591887,  0.83819175]], dtype=float32), Array([ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "        0.09241819, -0.08388805], dtype=float32)], [Array([[ 0.6423273 ,  0.39472246, -0.42661452, ...,  0.68257403,\n",
      "         0.09241819, -0.08388805]], dtype=float32), Array([-0.54859734], dtype=float32)]]\n",
      "[[Array([ 1.5464869 ,  0.3962691 , -0.42661452, ...,  2.7505982 ,\n",
      "        2.5636942 , -0.08388805], dtype=float32), Array([ 1.1650674 ,  0.3825206 , -0.42661452, ...,  1.8388966 ,\n",
      "        1.5213861 , -0.08388805], dtype=float32)], [Array([[ 0.36326313,  0.67431045, -0.34833646, ..., -0.22690678,\n",
      "         0.78762126,  0.40378356],\n",
      "       [ 0.01716638,  0.8024769 , -0.50727034, ..., -0.8463812 ,\n",
      "         0.6829629 ,  0.5702553 ],\n",
      "       [ 0.9881719 , -0.49764788, -0.84586954, ..., -0.8564743 ,\n",
      "         0.01565915,  0.10867071],\n",
      "       ...,\n",
      "       [-1.1087832 , -0.99145937, -0.3602624 , ...,  0.7690158 ,\n",
      "        -0.6472999 , -0.5530937 ],\n",
      "       [-0.34826705, -0.7717601 , -0.55924153, ...,  0.23190388,\n",
      "         0.7317175 ,  0.02865171],\n",
      "       [-0.15132217,  0.7247027 , -0.23983073, ...,  0.9168691 ,\n",
      "         0.8778941 ,  0.83819175]], dtype=float32), Array([ 0.6423273 ,  0.39472246, -0.38720477, ...,  0.6195193 ,\n",
      "        0.0838808 , -0.07613865], dtype=float32)], [Array([[ 0.6423273 ,  0.39472246, -3.9425957 , ..., -1.758887  ,\n",
      "        -0.84029967, -0.51439095]], dtype=float32), Array([-0.64097524], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = jnp.array(1/1e4)\n",
    "\n",
    "def UpdateWeights(learning_rate, weights, gradients):\n",
    "    for j in range(len(weights)): ## Update Weights\n",
    "        weights[j][0] -= learning_rate * gradients[j][0] ## Update Weights\n",
    "        weights[j][1] -= learning_rate * gradients[j][1] ## Update Biases\n",
    "\n",
    "print(weights)\n",
    "#print(gradients)\n",
    "UpdateWeights(learning_rate, weights, gradients)\n",
    "print(weights)\n",
    "#print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f32011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Array([ 1.5464869 ,  0.3962691 , -0.42661452, ...,  2.7505982 ,\n",
      "        2.5636942 , -0.08388805], dtype=float32), Array([ 1.1650674 ,  0.3825206 , -0.42661452, ...,  1.8388966 ,\n",
      "        1.5213861 , -0.08388805], dtype=float32)], [Array([[ 0.36326313,  0.67431045, -0.34833646, ..., -0.22690678,\n",
      "         0.78762126,  0.40378356],\n",
      "       [ 0.01716638,  0.8024769 , -0.50727034, ..., -0.8463812 ,\n",
      "         0.6829629 ,  0.5702553 ],\n",
      "       [ 0.9881719 , -0.49764788, -0.84586954, ..., -0.8564743 ,\n",
      "         0.01565915,  0.10867071],\n",
      "       ...,\n",
      "       [-1.1087832 , -0.99145937, -0.3602624 , ...,  0.7690158 ,\n",
      "        -0.6472999 , -0.5530937 ],\n",
      "       [-0.34826705, -0.7717601 , -0.55924153, ...,  0.23190388,\n",
      "         0.7317175 ,  0.02865171],\n",
      "       [-0.15132217,  0.7247027 , -0.23983073, ...,  0.9168691 ,\n",
      "         0.8778941 ,  0.83819175]], dtype=float32), Array([ 0.6423273 ,  0.39472246, -0.38720477, ...,  0.6195193 ,\n",
      "        0.0838808 , -0.07613865], dtype=float32)], [Array([[ 0.6423273 ,  0.39472246, -3.9425957 , ..., -1.758887  ,\n",
      "        -0.84029967, -0.51439095]], dtype=float32), Array([-0.64097524], dtype=float32)]]\n",
      "MSE : 3865554944.00\n",
      "MSE : nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(weights)\n\u001b[1;32m     18\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mTrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(weights)\n",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m, in \u001b[0;36mTrainModel\u001b[0;34m(weights, X, Y, learning_rate, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrainModel\u001b[39m(weights, X, Y, learning_rate, epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 5\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mMeanSquaredErrorLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         gradients \u001b[38;5;241m=\u001b[39m CalculateGradients(weights, X, Y)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m## Update Weights\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m, in \u001b[0;36mMeanSquaredErrorLoss\u001b[0;34m(weights, input_data, actual)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mMeanSquaredErrorLoss\u001b[39m(weights, input_data, actual):\n\u001b[0;32m----> 2\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mBatchForwardPass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mpower(actual \u001b[38;5;241m-\u001b[39m preds, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m, in \u001b[0;36mBatchForwardPass\u001b[0;34m(weights, input_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBatchForwardPass\u001b[39m(weights, input_data):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#apply forward pass to each data point\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [ForwardPass(weights,input_data[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_data))]\n\u001b[1;32m      5\u001b[0m     preds \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(predictions)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBatchForwardPass\u001b[39m(weights, input_data):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#apply forward pass to each data point\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[43mForwardPass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_data))]\n\u001b[1;32m      5\u001b[0m     preds \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(predictions)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m, in \u001b[0;36mForwardPass\u001b[0;34m(weights, input_datapoint)\u001b[0m\n\u001b[1;32m      2\u001b[0m layer_out \u001b[38;5;241m=\u001b[39m input_datapoint\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(weights[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#print(weights[i])\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print(layer_out)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     layer_out \u001b[38;5;241m=\u001b[39m \u001b[43mLinearLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRelu_jit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m preds \u001b[38;5;241m=\u001b[39m LinearLayer(weights[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], layer_out)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m, in \u001b[0;36mLinearLayer\u001b[0;34m(weights, input_data, activation)\u001b[0m\n\u001b[1;32m      2\u001b[0m w, b \u001b[38;5;241m=\u001b[39m weights\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print(weights)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#print(input_data)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m activation(out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def TrainModel(weights, X, Y, learning_rate, epochs):\n",
    "    for i in range(epochs):\n",
    "        loss = MeanSquaredErrorLoss(weights, X, Y)\n",
    "        gradients = CalculateGradients(weights, X, Y)\n",
    "\n",
    "        ## Update Weights\n",
    "        for j in range(len(weights)):\n",
    "            weights[j][0] -= learning_rate * gradients[j][0] ## Update Weights\n",
    "            weights[j][1] -= learning_rate * gradients[j][1] ## Update Biases\n",
    "\n",
    "        if i%10 ==0: ## Print MSE every 100 epochs\n",
    "            print(\"MSE : {:.2f}\".format(loss))\n",
    "\n",
    "print(weights)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "TrainModel(weights, X_train,Y_train, learning_rate=1e-1, epochs=50)\n",
    "\n",
    "end = time.time()\n",
    "print(weights)\n",
    "\n",
    "print(f'Total time: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a5cf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9513324910>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDA0lEQVR4nO3dfVxUZf4//hccGAbTIW8S7/isbaXVtmlZGZafqNjos0X6YVHCSr92t5q7DxVvEZEMlbyt/W6mm1batiWKqN34sYzE3A0/ftP8bTd2b+mW4F0ygMDg4fz+uBYQBbyuYc6cMzOv5+Mxj3J8n5n3HMaZN9e5rvcVZhiGASIiIiKLhFudABEREYU2FiNERERkKRYjREREZCkWI0RERGQpFiNERERkKRYjREREZCkWI0RERGQpFiNERERkqQirE5BRX1+Pn376CZ06dUJYWJjV6RAREZEEwzBQUVGBXr16ITy89fGPgChGfvrpJ8TFxVmdBhEREXnh8OHD6NOnT6t/HxDFSKdOnQCIF+NyuSzOhoiIiGS43W7ExcU1fo+3JiCKkYZLMy6Xi8UIERFRgLnQFAtOYCUiIiJLsRghIiIiS7EYISIiIkuxGCEiIiJLsRghIiIiS7EYISIiIkuxGCEiIiJLsRghIiIiS7EYISK/03XgnXeAxESgTx8gNhaIjweWLAE8HquzIyJ/Uy5GPvjgAyQnJ6NXr14ICwvD5s2bL3hMcXExrr/+ekRFReHyyy/HmjVrvEiViAKBrgPbtwOjRgG//jVwzTXAHXcAt98O9O0LdOoEREQAd98NFBUBP/4IHD0K7N4NTJsGREUBTifQvTvwi1+IW2ws0K0bcOmlwP33i8fXdatfKRH5inI7+KqqKgwYMAAPP/wwUlJSLhh/8OBB3HPPPRg3bhz+9re/oaioCI8++ih69uyJpKQkr5ImInvQdeD994E1a4D9+4GyMuDEifPjPvtM7XFra4Fjx86//8QJ4Pvvgfx88WeXC/jVr4D//m9g4kTA4VB8AURkC2GGYRheHxwWhk2bNmH48OGtxsyYMQNvv/02Pv3008b77r//fpw6dQrbtm2Teh63242YmBiUl5dzbxoii1VXA1OmANu2icLA+08Q3+vVC5g0iYUJkV3Ifn+bPmekpKQEiYmJze5LSkpCSUlJq8fU1tbC7XY3uxGRdTweYOlSoGdPoEMHYMUK4OBBexUiAPDTT8D06eJST+/ewOLFnINCFAhML0ZKS0sRGxvb7L7Y2Fi43W5UV1e3eExeXh5iYmIab3FxcWanSUTn0HUxp2PwYPHlPnUqUFpqdVbyzi5MunUDFi1iYUJkV7ZcTZOZmYny8vLG2+HDh61OiShkeDzAmDHiSzwxEdizx+qM2u/ECWDGDPGaBg8WRRYnwBLZh+nFSI8ePVBWVtbsvrKyMrhcLkRHR7d4TFRUFFwuV7MbEZnL4wESEsQX9iuvBO+X9Z49osjq0AGYMyd4XydRIDG9GImPj0dRUVGz+7Zv3474+Hizn5qILkDXgXffBa66ShQhO3danZH/eDxAbi4QGQn8n//DSzhEVlIuRiorK7F//37s378fgFi6u3//fhw6dAiAuMQyevToxvhx48bhu+++w/Tp0/HFF1/g+eefx/r16zF58mTfvAIi8kp+vhgdSEoCvvjC6mysYxjA2rWiGBsxgiMlRFZQLkY++ugjXHfddbjuuusAABkZGbjuuuswZ84cAMCRI0caCxMAuPTSS/H2229j+/btGDBgAJYuXYrVq1ezxwiRRTwe0Zvj/vs5GnCuggLRkI2Xb4j8q119RvyFfUaI2s/jAe66y/+XYrp0AQYMECMQBw8ClZWApokVLgMHismyQ4cCzz0HbNoEfPcdcOYMEB4ONEwr+/lnoKLCv3mHhwNZWUBOjsiXiNTJfn+zGCEKAdOmiX1f/KFbN6BfP2D4cN82H2tYavzyy6J1/IkT/ilQIiKA118HUlPNfy6iYMNihIjg8QDXXQd8/rk5jx8WBlxxBXDjjWKE4447/DuK0FCgzJsH7Npl7nOlpgLr1nGUhEiFbTqwEpH/6bqYjBkVZU4hctNNwHvvAXV1wJdfAq++CvzmN/7/otY0cenpgw/EpZ133gFuvVUUSb5WUCAm/BYU+P6xiUIdixGiILNhgyhCfP2lGR4uRj9qa4H//V/gzjvtNUrQUJjs2iWKpK1bAV83b/Z4RJE3dapvH5co1LEYIQoSug6MHCluvlwJctVVYsTB4xG78wbCBnSaBvzXfwGHDoni6bbbfPv4S5eKyzZccUPkGyxGiILA+vWA0ylGRXzlttvEF/nnn4sRBzuNgqhwOIDiYvFaHnxQjPD4wsaNYgTqySdZlBC1F4sRogB3331AWpqYM+ELDz0kvriLiwNjFESWwwH89a9ihOe994DLL2//Y+o6MHcu0KkT55IQtQeLEaIANmgQ8Oabvnms1FRR0LzySnAVIefSNDHf5euvRRfaiIj2P2Z1tZhLMm1a+x+LKBSxGCEKQLoO9O8P7NvX/sdquByzYUPgXorx1siRQE0NkJ3tmxU4S5YAkya1/3GIQg2LEaIAU1gIdOwIfPVV+x7n6quD83KMKk0DnnpKrMDxRWOzP/0JiI/nPBIiFSxGiALI+vXA734nfptvj6lTgc8+C+0i5FyaJkaHamtFodYeu3eLya2+nFBMFMxYjBAFiEmTxETV9ujdW3zZLl7sk5SCksMhCrWMjPY9TsNSa84jIbowFiNENqfrwJVXiuH/9khOBv71L46GyFq6VIxstPd8LVkCTJ7sm5yIghWLESIb27BB7Fz75ZfeP4amiT1V3njDd3mFitRU4PRpMcLRHs8+K4pBImoZixEim5o6VXwJ1tV5/xjZ2eKyTHsv74QyTRNLgNs7l+Stt8RSbCI6H4sRIhuaNk1cJvBWv36iZ8hTT4Xecl2zNMwlue8+7x9j3z4WJEQtYTFCZDPr1ol5Bt66915xWYdFiDm2bBE/I2/byu/bJ4pFLv0lasJihMhGJk8G0tPbd7yvOrJS69LSRFv5fv28O/7rr8VcoMJC3+ZFFKhYjBDZxA03iImO3nA4RA+SZct8mhK1QdPECJS3E1Pr6kTPGBYkRCxGiGxh0CBg717vju3fX6z4GDHCtzmRnDfeAF57zfvjH3xQjLIQhTIWI0QWGzTI+z1mkpOBL77g/BCrpad73221uhpwOtmtlUIbixEiC11/vfeFyOuvs3eInaSmel9QGAa7tVJoYzFCZJFBg4CPP/bu2PXrgfvv920+1H6pqeJn460lS0R/GaJQw2KEyAI33ODdiEhYmPiy4/wQ+xoxAti40fulvw1t6IlCCYsRIj9LTvZ+sioLkcCQktK+pb+jRrEPCYUWFiNEfjRxomgLrkrTxG/bqam+z4nM0bD099571Y89cwa49loWJBQ6WIwQ+UlyMvB//6/6cZomlu6mpPg+JzLfm2+KIlTV558DF10EFBT4Piciu2ExQuQHN97o3YgIIC7NtHcbe7KWt7v21taKy3LTp/s8JSJbYTFCZLLJk4GPPlI/LjxcXJrhiEhweOMN7zfZW7yYk1opuLEYITLR66971+K9d28xAZKFSHDZssX7bq3p6ZxDQsGLxQiRSaZOFasiVEVEAD/8wK6qwSo93buCRNfFBn1EwYjFCJEJpkwR/SK8kZ/PQiTYpad7d8lm40Zx2Y8o2LAYIfKxqVO92z33oos4RySUbNni3aRWbyfDEtkZixEiH9qwwbsRkZtvBsrLWYiEmjfeACZNUj/urbfECi2iYMFihMhHdB0YPVr9uBtuAEpKeGkmVD3zjHcFyUcfeb86h8huWIwQ+ch//idQU6N2zO9+B/y//2dOPhQ4nnnGu06tb74p5hgRBToWI0Q+MGUK8OGHase4XPwioSZvvundXJCHHuKSXwp8LEaI2mn9eu8mrK5ezUsz1Jw3c0jq6oBbbzUlHSK/YTFC1A4bNnjX+2HaNO6+Sy3zZg7J7t1i7hFRoGIxQuSlwkJg5Ei1YyIjRQGzaJE5OVFweOYZscJKxd69nNBKgSvMMAzD6iQuxO12IyYmBuXl5XC5XFanQwRdB5xOsdW7itOngehoc3Ki4OLte2zdOnZqJfuQ/f7myAiRF269Vf1LYuRIFiIkT9PE3kaqHnyQE1op8LAYIVKUkSGu0auIjPR+gzQKXampYqWWijNnOKGVAg+LESIF+fnier6q117jyhnyzpIlnNBKwY/FCJGkggLvduGdNk38hkvkLW+aou3dy4KEAgeLESIJhYViKW59vdpxr73GlTPkG2++CfTrp3bM3r3ql3mIrMDVNEQXoOvAxRcDlZVqx02a5N0lHaLW6LqYBF1Xp3ZcbS3gcJiTE1FbuJqGyEfmzVMvRG64gYUI+Z6meTcR+q67fJ8LkS+xGCFqg64D8+erHXPvvdz8jsyTmgpMnqx2zM6d3AeJ7I3FCFEb7r9fbUh88mRxbZ/ITMuWqU9ovf9+MQmbyI5YjBC1IjlZ7cM7O9u7DfOIvOHNhNa0NLEdAZHdsBghasGwYcBbb8nHO51ATo55+RC15PPP1eLr60Un4MJCc/Ih8haLEaJz5OeLrdxVzJjBpmbkf5om9qJRNWYMW8aTvbAYITqLrou9PVRER4tLNERWSEsTI3kqKiuB9HRz8iHyBosRorOkp6tvgPfKKxwVIWtt3iz2TFKxYQPnj5B9sBgh+rf8fPUP56lT2eqd7GHpUvVLNqNH83IN2YNXxcjy5cvRt29fOJ1ODB48GHv27Gkz/tlnn0X//v0RHR2NuLg4TJ48GTU1NV4lTGSGwkKx9FHFpEnA4sWmpEPklbQ04Mkn5eNrarzbb4nI15SLkfz8fGRkZCAnJwf79u3DgAEDkJSUhKNHj7YY/9prr2HmzJnIycnBgQMH8OKLLyI/Px+zZs1qd/JEvqDrwAMPqB0TH88Oq2RPs2eLeUyy1q9n/xGynnIxsmzZMjz22GMYO3Ysrr76aqxcuRIdOnTASy+91GL8hx9+iFtuuQWjRo1C3759cddddyE9Pf2CoylE/pKeLn5DlBURAezaZV4+RO2hacD06WrHPPAAL9eQtZSKEY/Hg7179yIxMbHpAcLDkZiYiJKSkhaPGTJkCPbu3dtYfHz33XfYunUrfvvb37YjbSLf8HjU54m8+ionrJK9ZWeL3jeyPB5xiYfIKkrFyPHjx6HrOmJjY5vdHxsbi9LS0haPGTVqFJ566inceuutiIyMxGWXXYaEhIQ2L9PU1tbC7XY3uxGZ4bLL1OKHDeOHNtmfpolVXio2bhQTsomsYPpqmuLiYixYsADPP/889u3bh8LCQrz99tvIzc1t9Zi8vDzExMQ03uLi4sxOk0JQcjLwr3/Jx48YIZZQEgWCESOAKVPUjlm6lPNHyBphhmEYssEejwcdOnRAQUEBhg8f3nj/mDFjcOrUKWzZsuW8Y4YOHYqbb74Zi89advDqq6/i8ccfR2VlJcLDz6+HamtrUVtb2/hnt9uNuLg4lJeXw+VyyaZL1KopU9T2kXE4gNOneXmGAk9Cgti1V1Z0NFBRwfc6+Ybb7UZMTMwFv7+VRkYcDgcGDRqEoqKixvvq6+tRVFSE+Pj4Fo85ffr0eQWH9u93eWt1UFRUFFwuV7Mbka8UFKhvaDdzJj+cKTC9+65afHU1MG+eObkQtUb5Mk1GRgZWrVqFtWvX4sCBAxg/fjyqqqowduxYAMDo0aORmZnZGJ+cnIwVK1Zg3bp1OHjwILZv347s7GwkJyc3FiVE/uLNMt6ICGDOHHPyITKbwyE2x1Mxfz5X15B/RagekJaWhmPHjmHOnDkoLS3FwIEDsW3btsZJrYcOHWo2EjJ79myEhYVh9uzZ+PHHH3HJJZcgOTkZ8+fP992rIJI0apRYOaDib3/jqAgFttdeE/OdZN/7dXXAf/4n8I9/mJoWUSOlOSNWkb3mRNQWjweIilI7JjlZfQdfIjsqKBCTWlVkZIhJrUTeMmXOCFEgu+46tfh+/ViIUPBITVVfXbNsGTfTI/9gMUIhISMD+Pxz+fiICLV4okCwZAkwebLaMdxMj/yBxQgFvYIC9X1kXn+d80QoOC1bJpb7yqqpUd9EkkgVixEKaroufrNTkZoqbkTB6p131OILCtidlczFYoSC2qhRom+CrIgIYN068/IhsgOHQ30yK7uzkplYjFDQKigQ26Or4CZ4FCpefx2IjFQ75pFHOH+EzMFihIKSN5dnhgzhJngUOjRN9NBR4XYDxcWmpEMhjsUIBaV589Quz0RGAh98YF4+RHY0YoT6XJBx48zJhUIbixEKOrquvrcGu6xSqFq8WG3C9jffqPcrIboQFiMUdObOBc6ckY+fOlV9Mh9RMFm3TkzelrVsGSezkm+xGKGgUlAA5ObKx990k/jNkCiUaRqQlaV2zKhRnMxKvsNihIJGYaH6CMeCBebkQhRosrPFkl9ZdXWiICHyBRYjFBR0HXjsMbVjXC61TpREwUzTgL/+Ve2Y9evVd8EmagmLEQoKxcXAyZNqx7z4IietEp1t5EixxF3F3XebkwuFFhYjFBSef14tfsoUtnwnaskHH6hdrtmxgzv7UvuxGKGAV1gobrJGjBC7lxLR+bxphsadfam9WIxQQNN1tUl00dGiDTYRtS41FcjIkI+vqVFbxUZ0LhYjFNCGDgVqa+XjZ8zgPBEiGUuXAldcIR+/cCFHR8h7LEYoYE2ZApSUyMd36gTMnm1ePkTBZsUK+diaGiA93bxcKLixGKGAVFAgukCqWLOGoyJEKhISRBEva8MGYPp009KhIMZihAKOroutzFXk5AApKebkQxSsNE0sgVexZAl7j5A6FiMUcIqLxVbmsqKjRXdJIlI3YoToPyLLMICkJPPyoeDEYoQCzvjxavEvv8zLM0Tt8dprQMeO8vHFxdxIj9SwGKGAsn498PXX8vFDhgBpaeblQxQKNA1Yu1btmEce4eoaksdihAKGrgMPPigfHx4uukkSUfulpKhd7nS7gQceMC8fCi4sRihgjBoldgqVNWcOL88Q+VJODhAVJR+fn89W8SSHxQgFhIICcYlGVlQUe4oQ+Zo3O/vycg3JYDFCtqfrYu8LFa+8wlERIjOMGCEaDsqqqBATWonawmKEbG/ePKC6Wj5+yBC1pYhEpGbJEmDwYPn4rCzzcqHgwGKEbE3X1TbgiozkpFUif5g/Xz72f/+XS32pbSxGyNbmzlW73vzaa7w8Q+QPCQmA0ykf//DDnDtCrWMxQral62q/fY0YIbY+JyLzaZrYBVtWRYXaKCeFFhYjZFvp6UB9vVxseDjw+uvm5kNEzWVni+0WZM2dCxQWmpcPBS4WI2RLHo9af4KHHuLlGSJ/0zSxck3F44/zcg2dj8UI2dLdd6vFv/CCOXkQUdtSU8UlUlknTqhdfqXQwGKEbKegANixQz5+5EjA4TAvHyJq2+uvq3Vmzcvj6Ag1x2KEbEXX1faziIwUK2iIyDqaBsyaJR9fUyP6BxE1YDFCtjJ3rpgvIuvVVzlXhMgOsrKArl3l4xcu5OgINWExQrah68CCBfLxt9zCTqtEdqFpanO3qqu5qy81YTFCtvHAA/K/KYWHAzt3mpsPEalJSRE3Wfn57MxKAosRsgWPR3wwyXrwQV6eIbKjJ55Qix89mpdriMUI2YTqUt5Vq8zJg4jaJyEB6NJFPr66mpNZCYiwOgHL6DpQVCQ69nz/vViXVl8PlJUBlZViund9vfj1OyoKMAygtlasIb3kEuDii0VMTY34tT4sDOjWDSgvB6qqgI4dgX79gL59gZMngU8/BY4cEY9pGOc/fng40KGD+P/aWhFTVyf+pZ45I543PFw8z0UXAd27i+N/+EHkq2li9lhsLHDqFHD0qDje6RSPFxEhHr9r16bHPX1aPE/HjuLxfv4ZOHZMnJvOncXzulxAr16izeKPP4q8IyPFYzgc4s+1tSK37t3FOfjmG/H8ERHi9YeHiz+7XOJxT50SudfXAydO4PTxKqwqj4SBMIQhDKdxEWrgQDWicAlOIOzfP7IaROASnEQnpw5Hv47iZ1BbK/I+c0acA6cT6NlTnKfaWvHfjh2BQ4fEzyk6WuR/+rTIXddFfg2bbNTWivu6dxe5//wzUFoqzl23buI5jh0DOnUCrrlG5LB3L/Ddd+L1du0qzmlZWdPPKSys6ZjOncVjut1N75djx0T+kZEiR10Xj9W5s3gtgMi1IceGx2p4riNHxN9XVoq/DwsT57a6Wvw3IkK87g4dxM/M42n62TcwDHHc2cLCxP0N78u6OnH/JZc0vc8No+l8Njxew3u04bnCwsR5MAzg4EGRZ8M593jE42paUyvPs38uZ9935ox4LQ6HOKauTvy5S5emxzKMpr9v+Dfb8HidOze993Vd/OwajmvIv+HcNfybcTrFaz99uuk8REeL/546JX4WmiYe68wZEdfw97W1oqnG2e+x8PDm5wZo/v+xsU3nqa5O/Pnyy4Hjx8V7rKpKPH7Da2nIq+ExTp4UeXTvDgwdCtx8s9il7p//FO+Thp9jwzmJimqeT3W1eHyHQ7xPq6qaPqPOfn80/HsPDxevExD/vn/4AVpdHQ5GOvH/4RJUIxqd8TM6oQoVuAinEINYHEVXnICGM9ARiZPoCs+TkajP9yA8PFz8u3K5mj4zG96DPXqIm2GIz5OqKnF+q6ub/wwazlHDz6GmRryWsz8nG15rXZ2Iu+giEet0Nn2mN/xs6upEPldfLX4uhw+LHCIixGMYhrid/Rne8POvqRH5NHyuaBpw6aVNnyUXXSQ+n0pLxedrr17i5naL444dE7fKyqb+BWf/HBre47ou3iv/8R/ifel2i/ja2ubv7Z49xb+XkyfFazk7586dgWHDgIkTLemVEGYYZ38i2ZPb7UZMTAzKy8vhcrna/4CFhcCYMU0f3kRERCSKlqlTgUWLfPJwst/foTcyUlgI/O53VmdBRERkP4YBLF4s/t9HBYmM0JozouvAH/9odRZERET2tnSpWtOndgqtYmTXLuCnn6zOgoiIyN7q64Hnn/fb04VWMXLkiNUZEBERBYZvv/XbU4VWMdKwMoGIiIjadtllfnuq0CpGhg4Vy6aIiIiodeHh6h3s2vN0fnsmO9A04M9/tjoLIiIie5syxa/9RkKrGAHExgkbN4pGM0RERNQkLAyYNs2vy3qBUOwzAoiCZNgwdmD1cwfW+k4uvLW7MzrjFMJQD6Ae3XACnVCFGpzfgbUWURhy+YmmijkiQpxLXRc5swMrO7CyA6vtOrA2fu5ccol4rIbHuegifHMyBqcPnd+BtRaRiIAHYQjHZ7gG5XDhGnyKQbFH0MHJDqzswGoTPu/ASpYoKgISE+Xj8/OBkSPNy4eI/KuhBpRtfn399aLWp8Al+/0depdpyDIqS9aHDGEhQhRsNA1Yu1Y+ft8+YP168/Ih+2AxQn5RWChuMjQN+OADc/MhImukpIgrAbJ+/3sxokLBjcUImU7Xxb6EsoYNEwUJEQWn4cPlY0+dEs2zKbh5VYwsX74cffv2hdPpxODBg7Fnz54240+dOoUJEyagZ8+eiIqKQr9+/bB161avEqbAM2+e2gbJflzaTkQWGDoUiImRj2/Yt42Cl3Ixkp+fj4yMDOTk5GDfvn0YMGAAkpKScPTo0RbjPR4PfvOb3+D7779HQUEBvvzyS6xatQq9e/dud/Jkf7oOLFwoH9+1K5CQYFo6RGQDmgb85S/y8Vu3qo2mUOBRLkaWLVuGxx57DGPHjsXVV1+NlStXokOHDnjppZdajH/ppZdw8uRJbN68Gbfccgv69u2L2267DQMGDGh38mR/ubli9ZusF17gJRqiUJCWBtx3n3z8li2czBrMlIoRj8eDvXv3IvGs9Znh4eFITExESUlJi8e88cYbiI+Px4QJExAbG4trrrkGCxYsgN7GjKTa2lq43e5mNwo8hYXA3Lny8Tk5YnIbEYWGLVvUCpKxYzmZNVgpFSPHjx+HruuIjY1tdn9sbCxKS0tbPOa7775DQUEBdF3H1q1bkZ2djaVLl2LevHmtPk9eXh5iYmIab3FxcSppkg3oOvD44/LxTieQnW1ePkRkT1u2AHfdJRd7+jRQXGxqOmQR01fT1NfXo3v37njhhRcwaNAgpKWlISsrCytXrmz1mMzMTJSXlzfeDh8+bHaa5GPFxaI5oqwZM3h5hihU/dd/yce28dVBAUypGOnWrRs0TUNZWVmz+8vKytCjR48Wj+nZsyf69esH7axvmquuugqlpaXwNLTcPUdUVBRcLlezGwWW2bPlYzt25KgIUShTWUG3aRMv1QQjpWLE4XBg0KBBKCoqaryvvr4eRUVFiI+Pb/GYW265Bd988w3q6+sb7/vqq6/Qs2dPOCzof0/mKygAdu+Wj1+7lqMiRKHM4QBGjJCL1XUgPd3cfMj/lC/TZGRkYNWqVVi7di0OHDiA8ePHo6qqCmPHjgUAjB49GpmZmY3x48ePx8mTJzFx4kR89dVXePvtt7FgwQJMmDDBd6+CbEPXgfHj5eOffJKTVokIeP11+V9KNmxo2suOgoPyrr1paWk4duwY5syZg9LSUgwcOBDbtm1rnNR66NAhhIc31ThxcXF45513MHnyZFx77bXo3bs3Jk6ciBkzZvjuVZBt7NolNhiV4XSqXc4houClacB//7cYWZUxbhzQSkcJCkDctZd8KjkZeOstudjUVPEbDhERoLazt9MpOjvzEq+9cdde8ruCAvlCBBC/2RARNUhIADp0kIutqQHmzzc1HfIjFiPkE7oOPPCAfDzbvhPRuTQNePll+fjFi7myJliwGCGfGDVKbUIZ274TUUtGjgRuuUUutrJS7Zcgsi8WI9RuHo/anhFz53IFDRG1budOICpKLjY/n3PPggGLEWq3556Tj+3UCcjKMi8XIgp8mgbMmiUf/+ijvFwT6FiMULutWCEfm5HByzNEdGFZWaI7swy3m5NZAx2LEWqXggLgm2/kYiMi2PadiORoGjBtmnw8J7MGNhYj5DVdV9tTIjOToyJEJC8rC5BtLVVZyR19AxmLEfLarl3AsWNysZGRQE6OufkQUXDRNODFF+XjVX45InthMUJeW7pUPnb2bI6KEJG61FTg5pvlYr/6Cpg61dx8yBxsB09eKSiQ32XT5QJOnmQxQkTeUWkTDwC1tWInYLIe28GTaXQdGD1aPn71ahYiROS9hAT5lTUA8PjjpqVCJmExQspyc4HqarnYe++VH0EhImqJ6sqaV1/lyppAw2KElOg6sHChfPyUKeblQkShIytL/tKLrgPz5pmbD/kWixFSUlwsdsuU0akTMHSoqekQUYjQNGDGDPn4p5/m6EggYTFCSlSalrHbKhH5Uk6O/GdKTQ27sgYSFiMkbcMGoKRELtbhYLdVIvItTRNtAmTl5XF0JFCwGCEpqito2G2ViMyQnQ1ER8vF1tQAo0aZmw/5BosRkpKbKz9XJCqKoyJEZA5NA9aulY9fv170RSJ7YzFCF6TrwKJF8vGzZnFUhIjMM2KEfFdWABg/npdr7I7FCF3Q/PnyfUWio8USPCIiM6ks3T1+XOylRfbFYoTapOtiEpis6dM5KkJE5ktIAJxO+fgffzQtFfIBFiPUJpW5ItHRnCtCRP6hacDMmfLxKrv/kv+xGKFWqc4VWbuWoyJE5D+zZ8uPjuzYwYmsdsZihFqlMlckPp570BCRf2maaCMga/RoTmS1KxYj1CJdBxYvlo/PzTUvFyKi1mRlye/oW13Nzyq7YjFCLSouBior5WJdLjGZjIjI31R39F24kKMjdsRihFr0/PPysatXc64IEVknK0t+7gj3rLEnFiN0noICYNMmuVjOFSEiq6nu6DtvHkdH7IbFCDVTWCiKC8OQi+f1VyKyA5U9a+rqgPR0c/MhNSxGqJGuA48/Lh/fsSPnihCRPWga8Mor8vEbNgAej3n5kBoWI9SouBg4cUI+fto0zhUhIvtITVXbs0blly8yF4sRarRihXxs167cg4aI7Edlz5q//Y1zR+yCxQgBEP8g33hDPv6FFzgqQkT2k5AAOBxysWfOcN6bXbAYIQBiqVtdnVxsSoq4ERHZjerKmkWLODpiByxGSHln3ieeMC8XIqL2ysmRH7mtrhbz5chaLEZIaWdedlslIrvTNLGJnizuNm49FiMhTteBBQvk4198kXNFiMj+srOByEi52JISsdSXrMNiJMTl5srPFYmPF0vniIjsTtOAWbPk4x99lHNHrMRiJITputg0ShZnnRNRIMnOBqKi5GLdbs4dsRKLkRBWXCw/VyQ6mnNFiCiwqI6OqPRaIt9iMRLCVP7hTZ/OuSJEFHiysuT7jmzezEs1VmExEqJUmpxFRHC2OREFJk0D7r1XLlbXeTnaKixGQtQDD8hPXL3vPo6KEFHgUumNNG8eR0eswGIkBG3YAOTny8ezyRkRBbKEBMDplIvVdWDUKFPToRawGAkxug6MHi0fzyZnRBToVFvEr18PeDzm5UPnYzESYlS6rQJsckZEwSE7W34iKwDcfbd5udD5WIyEENVuq2lpbHJGRMFB04DMTPn4HTvYldWfWIyEEJVuq9HRwN/+Zm4+RET+pDo6MmECJ7P6C4uREKHabZV9RYgo2Gga8Mor8vHHjgG7dpmXDzVhMRIiVLqtOhzsK0JEwSktDbjlFvn4H380LxdqwmIkRKh0W501i6MiRBS8du6U39H3xRfNzYUEFiMhQNeBN9+Ui42MBGbPNjcfIiIraZp8/yROZPUPFiMhIDdXfs08R0WIKBQMHy4fO2YMJ7KajcVIkNN1YNEiuVjOFSGiUDF0KNCli1xsdTX3rDEbi5EgN3+++Ickg3vQEFGo0DRg4kT5+Lw8jo6YyatiZPny5ejbty+cTicGDx6MPXv2SB23bt06hIWFYbjK+Bh5TdeBxYvl48eNMy8XIiK7ycqS37PG4xGb6JE5lIuR/Px8ZGRkICcnB/v27cOAAQOQlJSEo0ePtnnc999/j6lTp2Lo0KFeJ0tqiouBykq5WO5BQ0ShRnXPmqVLOTpiFuViZNmyZXjssccwduxYXH311Vi5ciU6dOiAl156qdVjdF3HAw88gLlz5+KXv/xluxImeSrzP1av5iUaIgo92dnyy3wrKtgEzSxKxYjH48HevXuRmJjY9ADh4UhMTERJSUmrxz311FPo3r07HnnkEannqa2thdvtbnYjNQUFQBs/kmbi44ERI8zNh4jIjjRNrCKUtWWLebmEMqVi5Pjx49B1HbGxsc3uj42NRWlpaYvH/P3vf8eLL76IVatWST9PXl4eYmJiGm9xcXEqaYY8XQck6z4AnCVORKEtO1vsxyVj5UpeqjGDqatpKioq8NBDD2HVqlXo1q2b9HGZmZkoLy9vvB0+fNjELINPcTEgO5jUsSPnihBRaNM0YO1audiaGv4CZ4YIleBu3bpB0zSUlZU1u7+srAw9evQ4L/7bb7/F999/j+Tk5Mb76uvrxRNHRODLL7/EZZdddt5xUVFRiIqKUkmNzvL88/Kx06ZxrggR0YgR4pK1zOXtRYvEaAo/O31HaWTE4XBg0KBBKCoqaryvvr4eRUVFiI+PPy/+yiuvxCeffIL9+/c33u677z7cfvvt2L9/Py+/mEDXgTfekIt1OMTSNiIiAu68Uy6uulqMQJPvKI2MAEBGRgbGjBmDG264ATfddBOeffZZVFVVYezYsQCA0aNHo3fv3sjLy4PT6cQ111zT7PiLL74YAM67n3wjNxc4c0YuNjmZlT0RUYOEBPleIitWyBcvdGHKxUhaWhqOHTuGOXPmoLS0FAMHDsS2bdsaJ7UeOnQI4eFs7GoFXRddAmWNH29eLkREgSYhQUxklelavXEjUFgIpKSYnlZICDMMw7A6iQtxu92IiYlBeXk5XC6X1enY1pNPAnPnysU6naIhGkdGiIiaqHyOdu0KlJXxc7Qtst/fHMIIEroOLFggHz9jBv8BERGdKztbrDKUceKE2P+L2o/FSJCYNw+oq5OLjYzk7rxERC1RWeYLiP2/2Hek/ViMBAFdBxYulI/PyuKoCBFRa1JS5C/VVFZyZY0vsBgJAsXFchOuALGcd/ZsU9MhIgp4WVnARRfJxar0dqKWsRgJAu+/Lx+bmclRESKiC9E0YNAgudg33+SlmvZiMRIENm+Wi4uI4FwRIiJZt94qF1dXx4ms7cViJMAVFACffy4Xe999HBUhIpJ1xx3ysXl5HB1pDxYjAUx1d94nnjAvFyKiYJOQAMi2tuIGeu3DYiSAzZ/P3XmJiMyiacCLL8rHc3TEeyxGApRq63fuzktEpC41Fbj5ZrlYj4ejI95iMRKg5s0Tw4IyXC7uzktE5C3ZzfMA0QmboyPqWIwEIF1Xm7m9ejVHRYiIvJWQIPbzklFXx9ERb7AYCUAqrd9vvhkYMcLcfIiIgpmmif28ZC1axNERVSxGAoxq63eV4UUiImpZdrbY10tGdTVbxKtiMRJgVFq/R0dzBQ0RkS9oGjBrlnz8ypXm5RKMWIwEGJU9EKZP51wRIiJfURkd2bKFl2pUsBgJILoOvPGGXKymsfU7EZEvqYyO1NXxMrkKFiMBZN484MwZudhhwzgqQkTka9nZYvdzGU8/zdERWSxGAoSuA0uXysez9TsRke9pmtjnS0ZNDSeyymIxEiB27QIqKuRinU5OXCUiMsu4cfKxK1aYl0cwYTESILZskY+dMYOXaIiIzKLSBO3tt3mpRgaLkQCg6/KbNUVHc+IqEZGZVJqg1dSodcwOVSxGAsD8+fKXaNau5agIEZHZsrPlR0cWL+boyIWwGLE5ld15772Xrd+JiPxB04DMTLnYykpOZL0QFiM2l5srvzvvlCnm5kJERE2ysuRHR2bPNjeXQMdixMZ0XWxHLaNTJ2DoUHPzISKiJpoG3HOPXOzu3cCGDebmE8hYjNhYbq787rxJSZwrQkTkb+PHy8eOGcO5I61hMWJTKqMigNq6dyIi8o2EBKBjR7nY6mrxSyadj8WITamMinB3XiIia2gaMG2afPyCBRwdaQmLERtSWUEDcHdeIiIrZWWJXwpl1NVxdKQlLEZsKDcX8HjkYh0ONjkjIrKSShM0QPyyydGR5liM2IzqXJHMTI6KEBFZbfZs+d18PR6OjpyLxYjNqMwV4agIEZE9qDRBA4BFizg6cjYWIzai68DChfLxHBUhIrKP7GwgMlIutrqaXVnPxmLERoqL5butclSEiMheNA2YNUs+/vnnzcsl0LAYsZEVK+RjOSpCRGQ/2dlARIRc7JYtvFTTgMWITeg68OabcrGaxlERIiI70jRg2DC5WF3nRNYGLEZsYv58+eW8w4ZxVISIyK5UWsRzIqvAYsQGVJfzPvGEebkQEVH7JCTIN0HjRFaBxYgN5OYCtbVysS4XW78TEdmZponO2LJU5gsGKxYjFlMdFXnxRV6iISKyO5Vlvhs3AoWF5uZjdyxGLKbS5Cw+HkhNNTcfIiJqP00Te9bIGjMmtOeOsBixkK4Dy5bJx3PWNRFR4Jg9G+jYUS62sjK0P+NZjFho1y6gokIuNjqac0WIiAKJpgFr18rHL1sWuqMjLEYstGWLfOz06ZwrQkQUaFJS5C+vV1SIX1JDEYsRi+g68Je/yMVGR7PJGRFRoBo3Tj72yBHz8rAzFiMWyc0V68tlvPIKR0WIiAJVQoJoyyDj669NTcW2WIxYQNeBvDy52Jtv5goaIqJApmmiLYOMnJzQXObLYsQCubnyrd8TE83NhYiIzJeaCkybJhcbist8WYz4mcqoCMAVNEREwWLRIrn5f6G4zJfFiJ/Nmyc/KsLlvEREwcUw5OIWLgyt0REWI36k62J3XllczktEFJpqatS+LwIdixE/Umn9HhnJ5bxERMFGZbR78eLQGR1hMeInui6G3WTNmsVRESKiYKOyzLeyEiguNjMb+2Ax4ifFxWLYTYbDwVERIqJgpLLMF2AxQj72/PPysZmZHBUhIgpWqamihxQ18aoYWb58Ofr27Qun04nBgwdjz549rcauWrUKQ4cORefOndG5c2ckJia2GR+MdF1+HxpN46gIEVGwmzdPLi48RIYMlF9mfn4+MjIykJOTg3379mHAgAFISkrC0aNHW4wvLi5Geno6duzYgZKSEsTFxeGuu+7Cjz/+2O7kA0VurvwkpGHDOCpCRBTsEhKArl0vHPfUU2JlZbALMwzZVc/C4MGDceONN+K5554DANTX1yMuLg5//OMfMXPmzAser+s6OnfujOeeew6jR4+Wek63242YmBiUl5fDJTvzxyZ0XfQLkV1F8957wJ13mpsTERFZr7AQ+N3v5GLXrwdGjDA3HzPIfn8rjYx4PB7s3bsXiWf1KA8PD0diYiJKSkqkHuP06dOoq6tDly5dWo2pra2F2+1udgtUKst52eSMiCh0pKQAc+fKxT76aHAv81UqRo4fPw5d1xEbG9vs/tjYWJSWlko9xowZM9CrV69mBc258vLyEBMT03iLi4tTSdM2VFu/s8kZEVFoueIKuTi3O7hX1vh1aszTTz+NdevWYdOmTXA6na3GZWZmory8vPF2+PBhP2bpOyob4nE5LxFR6OnZUz525Urz8rCaUjHSrVs3aJqGsrKyZveXlZWhR48ebR67ZMkSPP3003j33Xdx7bXXthkbFRUFl8vV7BZodF1siiSLy3mJiELP0KFAp05ysQUFYp5JMFIqRhwOBwYNGoSioqLG++rr61FUVIT4+PhWj1u0aBFyc3Oxbds23HDDDd5nG0CKi4HqarlYtn4nIgpNmgZMmSIfP2lScM4dUb5Mk5GRgVWrVmHt2rU4cOAAxo8fj6qqKowdOxYAMHr0aGRmZjbGL1y4ENnZ2XjppZfQt29flJaWorS0FJWVlb57FTakMpzG1u9ERKFr9mygY0e52MOHgV27zM3HChGqB6SlpeHYsWOYM2cOSktLMXDgQGzbtq1xUuuhQ4cQflaXlhUrVsDj8SA1NbXZ4+Tk5ODJJ59sX/Y2pevAO+/IxXJUhIgotGkasHat/DLfYGzTpdxnxAqB1mekuBi4/Xa52JwcIEhrMiIiUjBmDPDKKxeOGz1aFC+BwJQ+IyRHtmqNiuKoCBERCX36yMW9/nrwzRthMWKC996Ti0tP51wRIiISZPehqasTrSOCCYsRHyssBNaskYtto+8bERGFGJUO3Hl5wTU6wmLEh3QdePxx+fjevc3LhYiIAktCgtgWRIbHI7/zbyBgMeJD8+cDJ07IxcbFiWY3REREgLhsr7JD7/z5wTM6wmLER3QdWLxYPv7ZZzlfhIiImsvOFi0fZNTVBc/oCIsRH5k/H5Dt4zZ3rtitkYiI6GyaJhphylqwIDhGR1iM+IDKqEiXLkBWlrn5EBFR4FIZHfF4gmNlDYsRH1AZFZk4kZdniIiodaqjI4sWBf7oCDuwtpOuAxdfLFeMdOwInDrFYoSIiNqm62JlTV2dXPx77wF33mluTt5gB1Y/KS6WHxWZNo2FCBERXZjq6IjK5qx2xJGRdkpNBTZuvHCc0ymKFhYjREQkQ2V0JDISqK6233cMR0b8QNeBN9+Ui73pJvu9SYiIyL5URkcCfZkvi5F2mD9fzGSWceut5uZCRETBJzsbcDjkYgN5mS+LES+pNjm74w7zciEiouCkaUByslxsIC/zZTHiJZXlvC6X2gZIREREDcaPl48N1NERFiNe0HWxY6Ks1as5X4SIiLyTkCAWQcioqwvM0REWI17IzQVqauRi09KAESPMzYeIiIKXpgEzZsjHB2ITNC7tVaTronmZTDHC5bxEROQLug506CC/aMIuTdC4tNckxcXyoyL33stChIiI2k/TgMxM+fj33zcvFzOwGFFUXCwfO26caWkQEVGIyc4GIiLkYv/+d3Nz8TUWIyaJjuYKGiIi8h1NA4YNk4vdsyew5o2wGFH01VdycdOn8xINERH5luwy35oatZF8q7EYUVBQAKxff+G4jh3FcBoREZEvqSzzXbHC1FR8isWIJF0HHnlELpa78xIRkRk0TSyOkLFxI1BYaG4+vsJiRFJxMeB2y8VecYWpqRARUQhTWRwxZkxgzB1hMSJp9mz52J49zcuDiIhCW0IC0LWrXGxlZWB0ZGUxIqGgANi9Wy62Uydg6FBz8yEiotClacALL8jHL1xo/9ERFiMXoDJXBAAyMjhfhIiIzJWSAqSmysUGwsoaFiMXMH++/FwRp5OraIiIyD9U5o6wGAlgug4sXiwfn5nJUREiIvKPhATRYFNGUZGpqbQbi5E2FBeLyT8yXC4gK8vUdIiIiBqp7OZbUgJs2GBuPu3BYqQNKg1jVq/mqAgREfnX7NnyTdDsvMyXxUgrdB3YvFku9uqrgREjTE2HiIjoPJomP3ekutq+y3xZjLQiN1e+ghw+3NRUiIiIWiW7eR4A5OXZc3SExUgLdF38wGTdcYd5uRAREbVl6FDR40qGxwPMm2duPt5gMdKC3FzxA5MRHS1mNBMREVlB04ApU+Tj58+33+gIi5FzqI6KTJ/OiatERGSt2bOByEi52Lo6+80dYTFyDpVREYeDTc6IiMh6mgbMmiUfv2iRvUZHWIycRdeBZcvk49nkjIiI7CI7W350pLraXl1ZWYycZdcuoKJCLjYykqMiRERkH6qjIyq9tMzGYuQsmzbJx86axVERIiKyF5XRkXfftc+lGhYj/6broouqDM4VISIiO1IZHamoEFcE7IDFyL8VFwOnT8vFjh/PUREiIrKn7Gz5FvE//mhuLrJYjPybyrUzdlwlIiK70jQgPV0u9r33zM1FFosRqO1D06GD6HZHRERkV3feKRe3Zg1QWGhqKlJYjEBtH5q77+YlGiIisrfeveVj7bCbb8gXI7oOLFggH//EE+blQkRE5AtDhwJ9+sjFVlZa35E15IuR3FzRGlcG96EhIqJAoGnAn/4kH79ggbWjIyFdjOg6sHChfDz3oSEiokCRkgKkpsrFWr1fTUgXI8XFQE2NXCx7ixARUaAZN04+duFC60ZHQroYUVnOy46rREQUaBISxBQDGTU11u1XE7LFiK6LVrgyIiPF9sxERESBRNPEFANZ779vXi5tCdliRGVTvKwsjooQEVFgys4GIiLkYmV7bvlayBYjS5fKxTmdHBUhIqLApWnAfffJxX7+OVBQYG4+LQnJYqSgAHjrLbnYzEyOihARUWBT6ZE1erT/J7J6VYwsX74cffv2hdPpxODBg7Fnz5424zds2IArr7wSTqcTv/71r7F161avkvUFXRcnWobLJS7REBERBbKEBKBjR7nY6mpg3jxT0zmPcjGSn5+PjIwM5OTkYN++fRgwYACSkpJw9OjRFuM//PBDpKen45FHHsHHH3+M4cOHY/jw4fj000/bnbw3cnPFiZbx8MMcFSEiosCnacC0afLx/l7mG2YYhqFywODBg3HjjTfiueeeAwDU19cjLi4Of/zjHzFz5szz4tPS0lBVVYW3zroucvPNN2PgwIFYuXKl1HO63W7ExMSgvLwcLpdLJd1mdB3o3Fl+4uqOHey4SkREwUHXxeiIbH+t996T33CvNbLf30ojIx6PB3v37kViYmLTA4SHIzExESUlJS0eU1JS0iweAJKSklqNB4Da2lq43e5mN19QWUHjcnF3XiIiCh6aBsyYIR/vz54jSsXI8ePHoes6YmNjm90fGxuL0tLSFo8pLS1VigeAvLw8xMTENN7i4uJU0mzVkSPysZMn8xINEREFl+xs0TvLbmy5miYzMxPl5eWNt8OHD/vkcXv2lIuLjmbrdyIiCj6aJjqKy/DnNAWlYqRbt27QNA1lZWXN7i8rK0OPHj1aPKZHjx5K8QAQFRUFl8vV7OYLslsqv/IKR0WIiCg4ZWdfeGVN1642LkYcDgcGDRqEoqKixvvq6+tRVFSE+Pj4Fo+Jj49vFg8A27dvbzXeTA1bKoeFtR4zbZr8LodERESBRtOAtWvbjnnhBf/+Uq58mSYjIwOrVq3C2rVrceDAAYwfPx5VVVUYO3YsAGD06NHIzMxsjJ84cSK2bduGpUuX4osvvsCTTz6Jjz76CH/4wx989yoUpKSIpmfnjpBccgmwfj2waJElaREREflNSgqwcSPQu3fz+/v0EfenpPg3H8lu9U3S0tJw7NgxzJkzB6WlpRg4cCC2bdvWOEn10KFDCA9vqnGGDBmC1157DbNnz8asWbNwxRVXYPPmzbjmmmt89yoUpaQAw4aJ1TVHjoi5JEOH8tIMERGFDjt9Fyr3GbGCr/qMEBERkf+Y0meEiIiIyNdYjBAREZGlWIwQERGRpViMEBERkaVYjBAREZGlWIwQERGRpViMEBERkaVYjBAREZGlWIwQERGRpZTbwVuhoUms2+22OBMiIiKS1fC9faFm7wFRjFRUVAAA4uLiLM6EiIiIVFVUVCAmJqbVvw+IvWnq6+vx008/oVOnTggLC/PZ47rdbsTFxeHw4cPc86YFPD9t4/lpG89P63hu2sbz07ZAOj+GYaCiogK9evVqtonuuQJiZCQ8PBx9+vQx7fFdLpftf6BW4vlpG89P23h+Wsdz0zaen7YFyvlpa0SkASewEhERkaVYjBAREZGlQroYiYqKQk5ODqKioqxOxZZ4ftrG89M2np/W8dy0jeenbcF4fgJiAisREREFr5AeGSEiIiLrsRghIiIiS7EYISIiIkuxGCEiIiJLBX0xsnz5cvTt2xdOpxODBw/Gnj172ozfsGEDrrzySjidTvz617/G1q1b/ZSpNVTOz5o1axAWFtbs5nQ6/Zit/3zwwQdITk5Gr169EBYWhs2bN1/wmOLiYlx//fWIiorC5ZdfjjVr1piep1VUz09xcfF5752wsDCUlpb6J2E/ysvLw4033ohOnTqhe/fuGD58OL788ssLHhcqnz3enJ9Q+uxZsWIFrr322saGZvHx8fif//mfNo8JhvdOUBcj+fn5yMjIQE5ODvbt24cBAwYgKSkJR48ebTH+ww8/RHp6Oh555BF8/PHHGD58OIYPH45PP/3Uz5n7h+r5AUTHvyNHjjTefvjhBz9m7D9VVVUYMGAAli9fLhV/8OBB3HPPPbj99tuxf/9+TJo0CY8++ijeeecdkzO1hur5afDll182e/90797dpAyts3PnTkyYMAG7d+/G9u3bUVdXh7vuugtVVVWtHhNKnz3enB8gdD57+vTpg6effhp79+7FRx99hDvuuAPDhg3DZ5991mJ80Lx3jCB20003GRMmTGj8s67rRq9evYy8vLwW40eOHGncc889ze4bPHiw8fvf/97UPK2ien5efvllIyYmxk/Z2QcAY9OmTW3GTJ8+3fjVr37V7L60tDQjKSnJxMzsQeb87NixwwBg/Pzzz37JyU6OHj1qADB27tzZakyoffacTeb8hOpnT4POnTsbq1evbvHvguW9E7QjIx6PB3v37kViYmLjfeHh4UhMTERJSUmLx5SUlDSLB4CkpKRW4wOZN+cHACorK/GLX/wCcXFxbVbroSaU3jvtMXDgQPTs2RO/+c1v8I9//MPqdPyivLwcANClS5dWY0L5/SNzfoDQ/OzRdR3r1q1DVVUV4uPjW4wJlvdO0BYjx48fh67riI2NbXZ/bGxsq9epS0tLleIDmTfnp3///njppZewZcsWvPrqq6ivr8eQIUPwr3/9yx8p21pr7x23243q6mqLsrKPnj17YuXKldi4cSM2btyIuLg4JCQkYN++fVanZqr6+npMmjQJt9xyC6655ppW40Lps+dssucn1D57PvnkE3Ts2BFRUVEYN24cNm3ahKuvvrrF2GB57wTErr1kD/Hx8c2q8yFDhuCqq67CX/7yF+Tm5lqYGdld//790b9//8Y/DxkyBN9++y2eeeYZ/PWvf7UwM3NNmDABn376Kf7+979bnYotyZ6fUPvs6d+/P/bv34/y8nIUFBRgzJgx2LlzZ6sFSTAI2pGRbt26QdM0lJWVNbu/rKwMPXr0aPGYHj16KMUHMm/Oz7kiIyNx3XXX4ZtvvjEjxYDS2nvH5XIhOjraoqzs7aabbgrq984f/vAHvPXWW9ixYwf69OnTZmwoffY0UDk/5wr2zx6Hw4HLL78cgwYNQl5eHgYMGIA//elPLcYGy3snaIsRh8OBQYMGoaioqPG++vp6FBUVtXrtLT4+vlk8AGzfvr3V+EDmzfk5l67r+OSTT9CzZ0+z0gwYofTe8ZX9+/cH5XvHMAz84Q9/wKZNm/D+++/j0ksvveAxofT+8eb8nCvUPnvq6+tRW1vb4t8FzXvH6hm0Zlq3bp0RFRVlrFmzxvj888+Nxx9/3Lj44ouN0tJSwzAM46GHHjJmzpzZGP+Pf/zDiIiIMJYsWWIcOHDAyMnJMSIjI41PPvnEqpdgKtXzM3fuXOOdd94xvv32W2Pv3r3G/fffbzidTuOzzz6z6iWYpqKiwvj444+Njz/+2ABgLFu2zPj444+NH374wTAMw5g5c6bx0EMPNcZ/9913RocOHYxp06YZBw4cMJYvX25ommZs27bNqpdgKtXz88wzzxibN282vv76a+OTTz4xJk6caISHhxvvvfeeVS/BNOPHjzdiYmKM4uJi48iRI42306dPN8aE8mePN+cnlD57Zs6caezcudM4ePCg8c9//tOYOXOmERYWZrz77ruGYQTveyeoixHDMIw///nPxn/8x38YDofDuOmmm4zdu3c3/t1tt91mjBkzpln8+vXrjX79+hkOh8P41a9+Zbz99tt+zti/VM7PpEmTGmNjY2ON3/72t8a+ffssyNp8DUtRz701nI8xY8YYt91223nHDBw40HA4HMYvf/lL4+WXX/Z73v6ien4WLlxoXHbZZYbT6TS6dOliJCQkGO+//741yZuspfMCoNn7IZQ/e7w5P6H02fPwww8bv/jFLwyHw2Fccsklxp133tlYiBhG8L53wgzDMPw3DkNERETUXNDOGSEiIqLAwGKEiIiILMVihIiIiCzFYoSIiIgsxWKEiIiILMVihIiIiCzFYoSIiIgsxWKEiIiILMVihIiIiCzFYoSIiIgsxWKEiIiILMVihIiIiCz1/wNMsJpSEEXH7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train,Y_train,'bo')\n",
    "plt.plot(X_train,BatchForwardPass(weights,X_train),'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3c0b5611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : nan\n",
      "MSE : nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m layer_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m weights \u001b[38;5;241m=\u001b[39m InitializeWeights(layer_sizes, seed)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mTrainModelInBatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mMakePredictions\u001b[39m(weights, input_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[1;32m     11\u001b[0m     batches \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marange((input_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m### Batch Indices\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[79], line 40\u001b[0m, in \u001b[0;36mTrainModelInBatches\u001b[0;34m(weights, X, Y, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m X_batch, Y_batch \u001b[38;5;241m=\u001b[39m X[start:end], Y[start:end] \u001b[38;5;66;03m## Single batch of data\u001b[39;00m\n\u001b[1;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m MeanSquaredErrorLoss(weights, X_batch, Y_batch) \u001b[38;5;66;03m## Loss of batch\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mCalculateGradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss) \u001b[38;5;66;03m## Record Loss\u001b[39;00m\n\u001b[1;32m     43\u001b[0m UpdateWeights(learning_rate, weights, gradients) \u001b[38;5;66;03m## Update Weights\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[79], line 5\u001b[0m, in \u001b[0;36mCalculateGradients\u001b[0;34m(weights, input_data, actual)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCalculateGradients\u001b[39m(weights, input_data, actual):\n\u001b[1;32m      4\u001b[0m     Grad_MSELoss \u001b[38;5;241m=\u001b[39m grad(MeanSquaredErrorLoss)\n\u001b[0;32m----> 5\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m \u001b[43mGrad_MSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gradients\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/api.py:1179\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1179\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/api.py:1261\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1259\u001b[0m _check_scalar(ans)\n\u001b[1;32m   1260\u001b[0m tree_map(partial(_check_output_dtype_grad, holomorphic), ans)\n\u001b[0;32m-> 1261\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mvjp_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlax_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1262\u001b[0m g \u001b[38;5;241m=\u001b[39m g[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argnums, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m g\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/tree_util.py:302\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 302\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/api.py:2729\u001b[0m, in \u001b[0;36m_vjp_pullback_wrapper\u001b[0;34m(name, cotangent_dtypes, cotangent_shapes, io_tree, fun, *py_args_)\u001b[0m\n\u001b[1;32m   2724\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(arg) \u001b[38;5;241m!=\u001b[39m ct_shape:\n\u001b[1;32m   2725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of cotangent input to vjp pullback function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2727\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be the same as the shape of corresponding primal input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2728\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2729\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, ans)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/tree_util.py:302\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 302\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:146\u001b[0m, in \u001b[0;36mvjp.<locals>.unbound_vjp\u001b[0;34m(pvals, jaxpr, consts, *cts)\u001b[0m\n\u001b[1;32m    144\u001b[0m cts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ct \u001b[38;5;28;01mfor\u001b[39;00m ct, pval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cts, pvals) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pval\u001b[38;5;241m.\u001b[39mis_known())\n\u001b[1;32m    145\u001b[0m dummy_args \u001b[38;5;241m=\u001b[39m [UndefinedPrimal(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39minvars]\n\u001b[0;32m--> 146\u001b[0m arg_cts \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(instantiate_zeros, arg_cts)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:250\u001b[0m, in \u001b[0;36mbackward_pass\u001b[0;34m(jaxpr, reduce_axes, transform_stack, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[1;32m    247\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m get_primitive_transpose(eqn\u001b[38;5;241m.\u001b[39mprimitive)(\n\u001b[1;32m    248\u001b[0m       params, call_jaxpr, invals, cts_in, cts_in_avals, reduce_axes)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39mprimitive \u001b[38;5;129;01min\u001b[39;00m reducing_transposes:\n\u001b[0;32m--> 250\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m \u001b[43mreducing_transposes\u001b[49m\u001b[43m[\u001b[49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprimitive\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m get_primitive_transpose(eqn\u001b[38;5;241m.\u001b[39mprimitive)(\n\u001b[1;32m    254\u001b[0m       cts_in, \u001b[38;5;241m*\u001b[39minvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/pjit.py:1853\u001b[0m, in \u001b[0;36m_pjit_transpose\u001b[0;34m(reduce_axes, cts_in, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, in_positional_semantics, out_positional_semantics, keep_unused, inline, *primals_in)\u001b[0m\n\u001b[1;32m   1847\u001b[0m cts_out_treedef \u001b[38;5;241m=\u001b[39m cts_out_treedef_thunk()\n\u001b[1;32m   1848\u001b[0m transpose_out_shardings \u001b[38;5;241m=\u001b[39m prune_type(\n\u001b[1;32m   1849\u001b[0m     ad\u001b[38;5;241m.\u001b[39mZero,\n\u001b[1;32m   1850\u001b[0m     in_shardings,\n\u001b[1;32m   1851\u001b[0m     tree_unflatten(cts_out_treedef, [\u001b[38;5;28mobject\u001b[39m()] \u001b[38;5;241m*\u001b[39m cts_out_treedef\u001b[38;5;241m.\u001b[39mnum_leaves))\n\u001b[0;32m-> 1853\u001b[0m nz_cts_out \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals_and_nz_cts_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_in_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_out_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprimals_and_nz_cts_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_positional_semantics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_in_positional_semantics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_positional_semantics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_positional_semantics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(cts_out_treedef, nz_cts_out)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/core.py:2577\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2573\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2574\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2575\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2576\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/core.py:807\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/pjit.py:1291\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, in_positional_semantics, out_positional_semantics, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1290\u001b[0m   _allow_propagation_to_outputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_shardings)\n\u001b[0;32m-> 1291\u001b[0m compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_is_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_lower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_platform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1295\u001b[0m         _allow_propagation_to_outputs\u001b[38;5;241m=\u001b[39m_allow_propagation_to_outputs)\n\u001b[1;32m   1296\u001b[0m _most_recent_pjit_call_executable\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m compiled\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/pjit.py:1377\u001b[0m, in \u001b[0;36m_pjit_lower\u001b[0;34m(jaxpr, in_shardings, out_shardings, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1375\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m SameDeviceAssignmentTuple(in_shardings, da)\n\u001b[1;32m   1376\u001b[0m out_shardings \u001b[38;5;241m=\u001b[39m SameDeviceAssignmentTuple(out_shardings, da)\n\u001b[0;32m-> 1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pjit_lower_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/jax/_src/config.py:454\u001b[0m, in \u001b[0;36mConfig._trace_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m   \u001b[38;5;28msetattr\u001b[39m(Config, name, \u001b[38;5;28mproperty\u001b[39m(get_state))\n\u001b[1;32m    451\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _StateContextManager(name, help, update_thread_local_hook,\n\u001b[1;32m    452\u001b[0m                               validate_new_val_hook)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_trace_context\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    455\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a tuple of configuration values that affect tracing.\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m  These values are included in the cache key for linear_util.cache.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m  Values included in this set should also most likely be included in\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m  the C++ JIT state, which is handled separately.\"\"\"\u001b[39;00m\n\u001b[1;32m    461\u001b[0m   tls \u001b[38;5;241m=\u001b[39m jax_jit\u001b[38;5;241m.\u001b[39mthread_local_state()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "seed = jax.random.PRNGKey(42)\n",
    "learning_rate = jnp.array(1/1e3)\n",
    "epochs = 500\n",
    "layer_sizes = [10,10,1]\n",
    "\n",
    "weights = InitializeWeights(layer_sizes, seed)\n",
    "\n",
    "TrainModelInBatches(weights, X_train, Y_train, learning_rate, epochs, batch_size=32)\n",
    "\n",
    "def TrainModelInBatches(weights, X, Y, learning_rate, epochs, batch_size=32):\n",
    "    for i in range(epochs):\n",
    "        batches = jnp.arange((X.shape[0]//batch_size)+1) ### Batch Indices\n",
    "\n",
    "        losses = [] ## Record loss of each batch\n",
    "        for batch in batches:\n",
    "            if batch != batches[-1]:\n",
    "                start, end = int(batch*batch_size), int(batch*batch_size+batch_size)\n",
    "            else:\n",
    "                start, end = int(batch*batch_size), None\n",
    "\n",
    "            X_batch, Y_batch = X[start:end], Y[start:end] ## Single batch of data\n",
    "\n",
    "            loss = MeanSquaredErrorLoss(weights, X_batch, Y_batch) ## Loss of batch\n",
    "            gradients = CalculateGradients(weights, X_batch, Y_batch)\n",
    "            losses.append(loss) ## Record Loss\n",
    "\n",
    "            UpdateWeights(learning_rate, weights, gradients) ## Update Weights\n",
    "\n",
    "        if i % 10 == 0: ## Print MSE every 100 epochs\n",
    "            print(\"MSE : {:.2f}\".format(jnp.array(losses).mean()))\n",
    "\n",
    "def MakePredictions(weights, input_data, batch_size=32):\n",
    "    batches = jnp.arange((input_data.shape[0]//batch_size)+1) ### Batch Indices\n",
    "\n",
    "    preds = []\n",
    "    for batch in batches:\n",
    "        if batch != batches[-1]:\n",
    "            start, end = int(batch*batch_size), int(batch*batch_size+batch_size)\n",
    "        else:\n",
    "            start, end = int(batch*batch_size), None\n",
    "\n",
    "        X_batch = input_data[start:end]\n",
    "\n",
    "        preds.append(BatchForwardPass(weights, X_batch))\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "test_preds = MakePredictions(weights, X_test)\n",
    "\n",
    "test_preds = jnp.concatenate(test_preds).squeeze()\n",
    "\n",
    "train_preds = MakePredictions(weights, X_train)\n",
    "\n",
    "train_preds = jnp.concatenate(train_preds).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2c824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
